{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95b7066a",
   "metadata": {},
   "source": [
    "#### L'objectif principale de ce script est d'effectuer la phase de tests pour tester notre logique ML de notre app Streamlit, sans tester l’UI. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8ffc9e",
   "metadata": {},
   "source": [
    "### 1 - Importer les librairies nécessaires : \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9b7cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "import joblib       \n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb68b4b",
   "metadata": {},
   "source": [
    "### 2 - Charger les modéles ML a téster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "37531995",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"C:\\\\Users\\\\Amatek\\\\Downloads\\\\MACHINE LEARNING PROJET S1\\\\ml_final\\\\modele\\\\svm_model.pkl\"\n",
    "SCALER_PATH = \"C:\\\\Users\\\\Amatek\\\\Downloads\\\\MACHINE LEARNING PROJET S1\\\\ml_final\\\\modele\\\\scaler.pkl\"\n",
    "FEATURES_PATH = \"C:\\\\Users\\\\Amatek\\\\Downloads\\\\MACHINE LEARNING PROJET S1\\\\ml_final\\\\modele\\\\feature_names.pkl\"\n",
    "DATA_PATH = r\"C:\\Users\\Amatek\\Downloads\\MACHINE LEARNING PROJET S1\\ml_final\\data\\dataset_streamlit.csv\"\n",
    "\n",
    "model = joblib.load(MODEL_PATH)\n",
    "scaler = joblib.load(SCALER_PATH)\n",
    "feature_names = joblib.load(FEATURES_PATH)\n",
    "data = pd.read_csv(DATA_PATH, index_col=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601b0e16",
   "metadata": {},
   "source": [
    "### 3 - Classe de tests principale\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07f75a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestMLApp(unittest.TestCase):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0da8aec",
   "metadata": {},
   "source": [
    "###  4 - Test01 : Chargement des objets ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7534e209",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TestMLApp(unittest.TestCase):\n",
    "\n",
    "    def test_model_loaded(self):\n",
    "        self.assertIsNotNone(model)\n",
    "\n",
    "    def test_scaler_loaded(self):\n",
    "        self.assertIsNotNone(scaler)\n",
    "\n",
    "    def test_feature_names_loaded(self):\n",
    "        self.assertIsInstance(feature_names, list)\n",
    "        self.assertGreater(len(feature_names), 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8e5d2e",
   "metadata": {},
   "source": [
    "Ces tests permettent de vérifier que :\n",
    "* Le modèle existe .\n",
    "* Le scaler est chargé . \n",
    "* Les features sont bien une liste non vide. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f706dd4",
   "metadata": {},
   "source": [
    "### 05 -  Tester la cohérence des features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fe69ec14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestMLApp(unittest.TestCase):\n",
    "\n",
    "    def test_features_exist_in_data(self):\n",
    "        for feature in feature_names:\n",
    "            self.assertIn(feature, data.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182adb7c",
   "metadata": {},
   "source": [
    "Ce test permet d'éviter une erreur qui est classique en prod \"feature not found\" . "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385148a0",
   "metadata": {},
   "source": [
    "### 06 - Maintenant on vas tester sur la prédiction sur un cycle valide : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6e7984d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TestMLApp(unittest.TestCase):\n",
    "\n",
    "    def test_prediction_pipeline(self):\n",
    "        cycle_id = data.index[0]\n",
    "\n",
    "        X = data.loc[[cycle_id]]\n",
    "        X = X[feature_names]\n",
    "        X_scaled = scaler.transform(X)\n",
    "\n",
    "        pred = model.predict(X_scaled)[0]\n",
    "        proba = model.predict_proba(X_scaled)[0, 1]\n",
    "\n",
    "        self.assertIn(pred, [0, 1])\n",
    "        self.assertGreaterEqual(proba, 0)\n",
    "        self.assertLessEqual(proba, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae7cd27",
   "metadata": {},
   "source": [
    "L'importance de ces tests est de vérifier que : \n",
    "\n",
    "* La prédiction est bien binaire\n",
    "\n",
    "* La probabilité est entre 0 et 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bd2c89",
   "metadata": {},
   "source": [
    "### 07 : Tester la géstion des cycles inéxistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "632b80ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestMLApp(unittest.TestCase):\n",
    "\n",
    "    def test_invalid_cycle(self):\n",
    "        invalid_cycle = -999\n",
    "\n",
    "        self.assertNotIn(invalid_cycle, data.index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e607d9",
   "metadata": {},
   "source": [
    "Ce test permet de valider la logique de ce bout de code dans le script 'app.py' : \n",
    "    \n",
    "    if cycle_id not in data.index:\n",
    "    st.error(...)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b189da87",
   "metadata": {},
   "source": [
    "### 08 : Tester l'absence de NaN après normalisation : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "48d73203",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TestMLApp(unittest.TestCase):\n",
    "\n",
    "    def test_no_nan_after_scaling(self):\n",
    "        X = data.iloc[[0]][feature_names]\n",
    "        X_scaled = scaler.transform(X)\n",
    "\n",
    "        self.assertFalse(np.isnan(X_scaled).any())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39297f02",
   "metadata": {},
   "source": [
    "Ce test est très important pour éviter un crash silencieux du modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df76641",
   "metadata": {},
   "source": [
    "### 09 : Exécution des tests : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "43cc8757",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_no_nan_after_scaling (__main__.TestMLApp.test_no_nan_after_scaling) ... FAIL\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_no_nan_after_scaling (__main__.TestMLApp.test_no_nan_after_scaling)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Amatek\\AppData\\Local\\Temp\\ipykernel_9212\\1965074479.py\", line 7, in test_no_nan_after_scaling\n",
      "    self.assertFalse(np.isnan(X_scaled).any())\n",
      "AssertionError: True is not false\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.012s\n",
      "\n",
      "FAILED (failures=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=1 errors=0 failures=1>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "suite = unittest.TestLoader().loadTestsFromTestCase(TestMLApp)\n",
    "unittest.TextTestRunner(verbosity=2).run(suite)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "719fcc41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VS1_std        0\n",
      "VS1_max        0\n",
      "PS1_std        0\n",
      "PS1_max        0\n",
      "PS1_median     0\n",
      "PS2_std        0\n",
      "PS2_max        0\n",
      "PS2_median     0\n",
      "PS3_std        0\n",
      "PS3_max        0\n",
      "PS3_median     0\n",
      "PS5_mean       0\n",
      "PS5_max        0\n",
      "PS6_mean       0\n",
      "PS6_max        0\n",
      "FS1_median     0\n",
      "FS1_std        0\n",
      "FS1_max        0\n",
      "FS2_median     0\n",
      "FS2_std        0\n",
      "FS2_max        0\n",
      "TS1_mean       0\n",
      "TS1_max        0\n",
      "TS1_std        0\n",
      "TS2_mean       0\n",
      "TS2_max        0\n",
      "TS2_std        0\n",
      "TS3_mean       0\n",
      "TS3_max        0\n",
      "TS3_std        0\n",
      "TS4_mean       0\n",
      "TS4_max        0\n",
      "TS4_std        0\n",
      "EPS1_median    0\n",
      "EPS1_std       0\n",
      "EPS1_max       0\n",
      "CE_value       0\n",
      "CE_diff        0\n",
      "CP             0\n",
      "CP_delta       0\n",
      "SE             0\n",
      "SE_delta       1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data[feature_names].isna().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677262e3",
   "metadata": {},
   "source": [
    "Ces tests nous ont permis de détecter la présence de valeurs manquantes dans notre jeu de données. Celles-ci risquent de biaiser les résultats, c’est pourquoi il est nécessaire de les traiter avant de poursuivre l’analyse."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
